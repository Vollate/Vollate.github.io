---
title: 6.824-lab
categories: Distributed System
tags: Project
---
记录一下学习 MIT 6.824(现 6.5840) 的感悟

## Lab 1

没什么说的，coordinator-worker 结构，看看论文就知道了。worker 是提前装载好 map 和 reduce 函数的(我本来还以为是泛用型的)，只需要 RPC 传递对应文件参数即可。另外 server 退出后 worker 等到 RPC 错误后异常退出有点不优雅，加了个任务完成后通知所有 worker 退出。
crash test 测试的时候发现有概率失败，检查后发现是多重启了几次，把 timeout 从 5s 改到 10s 就好了，因为测试脚本是纯字符匹配。

## Lab 2

Lab2 分为两步，第一步确保 server 对 map 的写入没有数据竞争，没什么说的，RPC handler 挂锁就行。
第二步要处理网络传输不可靠导致的重传问题，也就是 server 执行操作后 client 没有收到 reply 重传 request 导致重复执行同一操作的问题。解决思路是为 client 分配唯一的 id, 并每次比较 sequence number 是否正确(类似 HTTP 的 seq-ack)。由于客户端为单线程工作，每次只会发送一个 RPC 请求直到成功，一次只需要存储上一次成功请求的返回值即可。并且需要快速清理过期 log, 因为在生产环境中可能会导致内存泄漏。
清理 log 有两个思路，一是定期整体扫描清理，但是坏处是在大集群下每次扫描所有 log 会暂停 RPC server 的工作造成服务大范围中断。第二种是每个 log 条目启动一个 goroutine 定时器删除，通过两层锁来减小影响数据的范围（好像数据库设计也是这么干但是 15445 还没时间学所以不是很清楚）
另外就是一个难受的地方，测试脚本在初始化 client 时 server 处于不可用状态，导致无法在初始化线程里请求 client ID,因此直接在 server 判断 ID 是否为 0, 为 0 则分配新 ID 给 client，非常不优雅。
PS: 写完想起来可以用 channel 来实现类似效果，毕竟 C++ call_once 也要一个 once_flag，就是不知道开销和直接用一个 atomic bool 哪个小。但是代码写完懒得动了(懒狗)

## Lab 3

